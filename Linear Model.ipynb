{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regresion (`Least Squares`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuration score 0.713\n",
      "testing accuration score 0.817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = load_boston()\n",
    "X = df.data\n",
    "y = df.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 66)\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "print('training accuration score {:.3f}'.format(lr.score(X_train, y_train)))\n",
    "print('testing accuration score {:.3f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.21562371e-01,  4.88527086e-02,  2.75554234e-02,  2.13319694e+00,\n",
       "       -1.92165700e+01,  3.25484414e+00, -5.02296307e-03, -1.66093472e+00,\n",
       "        2.97130376e-01, -1.19953846e-02, -9.93870868e-01,  8.37850481e-03,\n",
       "       -5.41527316e-01])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.10815624477739"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Ridge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuration score Ridge0.710\n",
      "testing accuration score Ridge0.818\n"
     ]
    }
   ],
   "source": [
    "rr = Ridge(alpha=1).fit(X_train, y_train) #using L2 regularization\n",
    "print('training accuration score Ridge{:.3f}'.format(rr.score(X_train, y_train)))\n",
    "print('testing accuration score Ridge{:.3f}'.format(rr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Lasso`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuration score Lasso: 0.712\n",
      "testing accuration score Lasso: 0.817\n",
      "Number of Feature used: 13\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ls = Lasso(alpha=0.01).fit(X_train, y_train) #using L2 regularization\n",
    "print('training accuration score Lasso: {:.3f}'.format(ls.score(X_train, y_train)))\n",
    "print('testing accuration score Lasso: {:.3f}'.format(ls.score(X_test, y_test)))\n",
    "print('Number of Feature used: %d' % np.sum(ls.coef_ != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CRIM', -0.11955542311798423),\n",
       " ('ZN', 0.04954048119806585),\n",
       " ('INDUS', 0.014291889188823171),\n",
       " ('CHAS', 1.9643327716471601),\n",
       " ('NOX', -15.970235263968421),\n",
       " ('RM', 3.2546515535631473),\n",
       " ('AGE', -0.007098339626442624),\n",
       " ('DIS', -1.6086082319822566),\n",
       " ('RAD', 0.2913152531290013),\n",
       " ('TAX', -0.01243546197276764),\n",
       " ('PTRATIO', -0.9566630187146957),\n",
       " ('B', 0.008402853141678759),\n",
       " ('LSTAT', -0.5479084202444382)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(df.feature_names, ls.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Linear Classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df = load_breast_cancer()\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.988\n",
      "Testing Score: 0.965\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.data, df.target)\n",
    "\n",
    "#Scaling data for better result\n",
    "scale = MinMaxScaler()\n",
    "X_train_scale = scale.fit_transform(X_train)\n",
    "X_test_scale = scale.transform(X_test)\n",
    "\n",
    "lgr = LogisticRegression(C=5).fit(X_train_scale, y_train)\n",
    "print('Training Score: {:.3f}' .format(lgr.score(X_train_scale, y_train)))\n",
    "print('Testing Score: {:.3f}' .format(lgr.score(X_test_scale, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score SVC: 0.991\n",
      "Testing Score SVC: 0.958\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC(C=3).fit(X_train_scale, y_train)\n",
    "print('Training Score SVC: {:.3f}' .format(svc.score(X_train_scale, y_train)))\n",
    "print('Testing Score SVC: {:.3f}' .format(svc.score(X_test_scale, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
